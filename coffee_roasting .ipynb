{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7104541c",
   "metadata": {},
   "source": [
    "# Neural Networks for Coffee Rosting\n",
    "# Outline\n",
    "- [ 1 - Packages ](#1)\n",
    "- [ 2 - Neural Networks](#2)\n",
    "  - [ 2.1 Problem Statement](#2.1)\n",
    "  - [ 2.2 Dataset](#2.2)\n",
    "  - [ 2.3 Tensorflow Model Implementation](#2.3)\n",
    "  - [ 2.4 NumPy Model Implementation (Forward Prop in NumPy)](#2.4)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4971ddca",
   "metadata": {},
   "source": [
    "## <a name=\"1\"></a>\n",
    "## 1 - Packages \n",
    "\n",
    "- [numpy](https://numpy.org/) is the fundamental package for scientific computing with Python.\n",
    "- [matplotlib](http://matplotlib.org) is a popular library to plot graphs in Python.\n",
    "- [tensorflow](https://www.tensorflow.org/) a popular platform for machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ba55a739",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b777c8",
   "metadata": {},
   "source": [
    "## <a name=\"2\"></a>\n",
    "## 2 - Neural Networks\n",
    "\n",
    "<a name=\"2.1\"></a>\n",
    "### 2.1 Problem Statement\n",
    "The problem statement is to develop a neural network model that can predict whether a coffee roasting is good or bad based on the temperature and duration of the roasting process. The dataset contains 200 examples, with each example consisting of two features - temperature and duration. The labels are binary, with 1 indicating a good roasting and 0 indicating a bad roasting.\n",
    "\n",
    "The objective is to develop a model that can accurately classify the examples into good and bad roasting without using traditional classification metrics such as accuracy, precision, and recall. Instead, we will focus on the model's ability to make correct predictions based on the given features and interpret the results based on the model's decision boundary. The model's performance will be evaluated based on its ability to correctly classify new examples and generalize to unseen data.\n",
    "<a name=\"2.2\"></a>\n",
    "### 2.2 Dataset\n",
    "\n",
    "\n",
    "- The `load_data()` function shown below loads the data into variables `X` and `y`\n",
    "â€‹\n",
    "\n",
    "- The data set contains 200 training examples of coffee roasting.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5770bac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_coffee_data():\n",
    "    \"\"\" Creates a coffee roasting data set.\n",
    "        roasting duration: 12-15 minutes is best\n",
    "        temperature range: 175-260C is best\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(2)\n",
    "    X = rng.random(400).reshape(-1,2)\n",
    "    X[:,1] = X[:,1] * 4 + 11.5          # 12-15 min is best\n",
    "    X[:,0] = X[:,0] * (285-150) + 150  # 350-500 F (175-260 C) is best\n",
    "    Y = np.zeros(len(X))\n",
    "    \n",
    "    i=0\n",
    "    for t,d in X:\n",
    "        y = -3/(260-175)*t + 21\n",
    "        if (t > 175 and t < 260 and d > 12 and d < 15 and d<=y ):\n",
    "            Y[i] = 1\n",
    "        else:\n",
    "            Y[i] = 0\n",
    "        i += 1\n",
    "\n",
    "    return (X, Y.reshape(-1,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "70c305cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 2) (200, 1)\n"
     ]
    }
   ],
   "source": [
    "X,Y = load_coffee_data();\n",
    "print(X.shape, Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10bca4db",
   "metadata": {},
   "source": [
    "### Normalize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "99157491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temperature Max, Min pre normalization: 284.99, 151.32\n",
      "Duration    Max, Min pre normalization: 15.45, 11.51\n",
      "Temperature Max, Min post normalization: 1.66, -1.69\n",
      "Duration    Max, Min post normalization: 1.79, -1.70\n"
     ]
    }
   ],
   "source": [
    "print(f\"Temperature Max, Min pre normalization: {np.max(X[:,0]):0.2f}, {np.min(X[:,0]):0.2f}\")\n",
    "print(f\"Duration    Max, Min pre normalization: {np.max(X[:,1]):0.2f}, {np.min(X[:,1]):0.2f}\")\n",
    "norm_l = tf.keras.layers.Normalization(axis=-1)\n",
    "norm_l.adapt(X)  # learns mean, variance\n",
    "Xn = norm_l(X)\n",
    "print(f\"Temperature Max, Min post normalization: {np.max(Xn[:,0]):0.2f}, {np.min(Xn[:,0]):0.2f}\")\n",
    "print(f\"Duration    Max, Min post normalization: {np.max(Xn[:,1]):0.2f}, {np.min(Xn[:,1]):0.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739d5a31",
   "metadata": {},
   "source": [
    "Tile/copy  data to increase the training set size and reduce the number of training epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dae57d10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200000, 2) (200000, 1)\n"
     ]
    }
   ],
   "source": [
    "Xt = np.tile(X,(1000,1))\n",
    "Yt= np.tile(Y,(1000,1))   \n",
    "print(Xt.shape, Yt.shape)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240e5dbd",
   "metadata": {},
   "source": [
    "<a name=\"2.3\"></a>\n",
    "### 2.3 Tensorflow Model Implementation\n",
    "\n",
    "The neural network we will use in this project is shown in the figure below. \n",
    "- This has two dense layers with sigmoid activations.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2acf44fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(1234)  # applied to achieve consistent results\n",
    "model = Sequential(\n",
    "    [\n",
    "        tf.keras.Input(shape=(2,)),\n",
    "        Dense(3, activation='sigmoid', name = 'layer1'),\n",
    "        Dense(1, activation='sigmoid', name = 'layer2')\n",
    "     ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d7da330e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " layer1 (Dense)              (None, 3)                 9         \n",
      "                                                                 \n",
      " layer2 (Dense)              (None, 1)                 4         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13\n",
      "Trainable params: 13\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "72060f76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1 params =  9 , L2 params =  4\n"
     ]
    }
   ],
   "source": [
    "L1_num_params = 2 * 3 + 3   # W1 parameters  + b1 parameters\n",
    "L2_num_params = 3 * 1 + 1   # W2 parameters  + b2 parameters\n",
    "print(\"L1 params = \", L1_num_params, \", L2 params = \", L2_num_params  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c4fec287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1(2, 3):\n",
      " [[ 0.8490095  -0.22524029  0.84335744]\n",
      " [ 0.4380275   0.94216895  0.20352936]] \n",
      "b1(3,): [0. 0. 0.]\n",
      "W2(3, 1):\n",
      " [[-0.11989427]\n",
      " [ 1.0561825 ]\n",
      " [ 0.13893509]] \n",
      "b2(1,): [0.]\n"
     ]
    }
   ],
   "source": [
    "W1, b1 = model.get_layer(\"layer1\").get_weights()\n",
    "W2, b2 = model.get_layer(\"layer2\").get_weights()\n",
    "print(f\"W1{W1.shape}:\\n\", W1, f\"\\nb1{b1.shape}:\", b1)\n",
    "print(f\"W2{W2.shape}:\\n\", W2, f\"\\nb2{b2.shape}:\", b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2c76e01a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "6250/6250 [==============================] - 14s 2ms/step - loss: 0.5215\n",
      "Epoch 2/10\n",
      "6250/6250 [==============================] - 12s 2ms/step - loss: 0.5210\n",
      "Epoch 3/10\n",
      "6250/6250 [==============================] - 12s 2ms/step - loss: 0.5211\n",
      "Epoch 4/10\n",
      "6250/6250 [==============================] - 13s 2ms/step - loss: 0.5211\n",
      "Epoch 5/10\n",
      "6250/6250 [==============================] - 13s 2ms/step - loss: 0.5211\n",
      "Epoch 6/10\n",
      "6250/6250 [==============================] - 12s 2ms/step - loss: 0.5210\n",
      "Epoch 7/10\n",
      "6250/6250 [==============================] - 13s 2ms/step - loss: 0.5211\n",
      "Epoch 8/10\n",
      "6250/6250 [==============================] - 12s 2ms/step - loss: 0.5210\n",
      "Epoch 9/10\n",
      "6250/6250 [==============================] - 13s 2ms/step - loss: 0.5210\n",
      "Epoch 10/10\n",
      "6250/6250 [==============================] - 13s 2ms/step - loss: 0.5210\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x221c612ef70>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(\n",
    "    loss = tf.keras.losses.BinaryCrossentropy(),\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    Xt,Yt,            \n",
    "    epochs=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e026d8",
   "metadata": {},
   "source": [
    "#### Updated Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d4c19241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1:\n",
      " [[-0.01730815 12.850388   14.410232  ]\n",
      " [-8.939161    0.33438644 11.966936  ]] \n",
      "b1: [-11.226457   13.396328    1.7587752]\n",
      "W2:\n",
      " [[-45.495697]\n",
      " [ 38.57591 ]\n",
      " [-43.28297 ]] \n",
      "b2: [-12.436532]\n"
     ]
    }
   ],
   "source": [
    "W1, b1 = model.get_layer(\"layer1\").get_weights()\n",
    "W2, b2 = model.get_layer(\"layer2\").get_weights()\n",
    "print(\"W1:\\n\", W1, \"\\nb1:\", b1)\n",
    "print(\"W2:\\n\", W2, \"\\nb2:\", b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3e9641ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = np.array([\n",
    "    [-8.94,  0.29, 12.89],\n",
    "    [-0.17, -7.34, 10.79]] )\n",
    "b1 = np.array([-9.87, -9.28,  1.01])\n",
    "W2 = np.array([\n",
    "    [-31.38],\n",
    "    [-27.86],\n",
    "    [-32.79]])\n",
    "b2 = np.array([15.54])\n",
    "model.get_layer(\"layer1\").set_weights([W1,b1])\n",
    "model.get_layer(\"layer2\").set_weights([W2,b2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041fa95d",
   "metadata": {},
   "source": [
    "#### Predict for new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cc80be01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 125ms/step\n",
      "predictions = \n",
      " [[9.625139e-01]\n",
      " [3.031606e-08]]\n"
     ]
    }
   ],
   "source": [
    "X_test = np.array([\n",
    "    [200,13.9],  # postive example\n",
    "    [200,17]])   # negative example\n",
    "X_testn = norm_l(X_test)\n",
    "predictions = model.predict(X_testn)\n",
    "print(\"predictions = \\n\", predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a46ecfef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decisions = \n",
      "[[1.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "yhat = np.zeros_like(predictions)\n",
    "for i in range(len(predictions)):\n",
    "    if predictions[i] >= 0.5:\n",
    "        yhat[i] = 1\n",
    "    else:\n",
    "        yhat[i] = 0\n",
    "print(f\"decisions = \\n{yhat}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "34b7c52f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decisions = \n",
      "[[1]\n",
      " [0]]\n"
     ]
    }
   ],
   "source": [
    "yhat = (predictions >= 0.5).astype(int)\n",
    "print(f\"decisions = \\n{yhat}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f895a47",
   "metadata": {},
   "source": [
    "### <a name=\"2.4\"></a>\n",
    "### 2.4 Numpy Model (Forward Prop in NumPy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3b3db3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "02e9ab88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the activation function\n",
    "g = sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0fa3cbd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_dense(a_in, W, b):\n",
    "    units = W.shape[1]\n",
    "    a_out = np.zeros(units)\n",
    "    for j in range(units):               \n",
    "        w = W[:,j]                                    \n",
    "        z = np.dot(w, a_in) + b[j]         \n",
    "        a_out[j] = g(z)               \n",
    "    return(a_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b8516b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_sequential(x, W1, b1, W2, b2):\n",
    "    a1 = my_dense(x,  W1, b1)\n",
    "    a2 = my_dense(a1, W2, b2)\n",
    "    return(a2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cadfcfb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "W1_tmp = np.array( [[-8.93,  0.29, 12.9 ], [-0.1,  -7.32, 10.81]] )\n",
    "b1_tmp = np.array( [-9.82, -9.28,  0.96] )\n",
    "W2_tmp = np.array( [[-31.18], [-27.59], [-32.56]] )\n",
    "b2_tmp = np.array( [15.41] )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b543356e",
   "metadata": {},
   "source": [
    "#### Predict for new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6af3a81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_predict(X, W1, b1, W2, b2):\n",
    "    m = X.shape[0]\n",
    "    p = np.zeros((m,1))\n",
    "    for i in range(m):\n",
    "        p[i,0] = my_sequential(X[i], W1, b1, W2, b2)\n",
    "    return(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5bc8b7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tst = np.array([\n",
    "    [200,13.9],  # postive example\n",
    "    [200,17]])   # negative example\n",
    "X_tstn = norm_l(X_tst)  # remember to normalize\n",
    "predictions = my_predict(X_tstn, W1_tmp, b1_tmp, W2_tmp, b2_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ef2de8e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decisions = \n",
      "[[1.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "yhat = np.zeros_like(predictions)\n",
    "for i in range(len(predictions)):\n",
    "    if predictions[i] >= 0.5:\n",
    "        yhat[i] = 1\n",
    "    else:\n",
    "        yhat[i] = 0\n",
    "print(f\"decisions = \\n{yhat}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "02762754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decisions = \n",
      "[[1]\n",
      " [0]]\n"
     ]
    }
   ],
   "source": [
    "yhat = (predictions >= 0.5).astype(int)\n",
    "print(f\"decisions = \\n{yhat}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48246ebb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
